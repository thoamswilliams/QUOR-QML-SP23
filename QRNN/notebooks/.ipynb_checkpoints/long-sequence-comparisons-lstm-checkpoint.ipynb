{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import RVQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to create a RNN or LSTM with roughly 837 or a larger one with roughly 100000 parameters, and compare it in the dna long sequence task implemented within RVQE.\n",
    "In either test the batch size is 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_t = lambda length: RVQE.datasets.all_datasets[\"dna\"](0, num_shards=0, batch_size=128, sentence_length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "def to_one_hot(labels, num_classes=2**3):\n",
    "    return torch.eye(num_classes)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [9120, 2783, 2057, 6549, 3201, 7063, 5243, 3102, 5303, 5819, 3693, 4884, 2231, 5514, 8850, 6861, 3106, 2378, 8697, 1821, 9480, 8483, 1633, 9678, 6596, 4509, 8618, 9765, 6346, 2969];\n",
    "LENGTHS = [5, 10, 20, 50, 100, 200, 500, 1000];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE_837 = 10\n",
    "NUM_LAYERS_837 = 1\n",
    "ARGS_837 = (HIDDEN_SIZE_837, NUM_LAYERS_837)\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "        This is a very simplistic LSTM setup. We found a single layer performs\n",
    "        much better than two layers with a smaller hidden size.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size: int, num_layers: int, io_size=2**3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=io_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.lin = nn.Linear(hidden_size, io_size)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.lin.reset_parameters()\n",
    "        for name, param in self.rnn.named_parameters():\n",
    "            # give an orthogonal start\n",
    "            if \"weight_hh\" in name:\n",
    "                # stacked\n",
    "                h = param.data.shape[1]\n",
    "                for i in range(4):\n",
    "                    torch.nn.init.orthogonal_(param.data[h*i : h*(i+1), :])\n",
    "            elif \"bias\" in name:\n",
    "                param.data.fill_(0)\n",
    "            elif \"weight_ih\" in name:\n",
    "                torch.nn.init.xavier_uniform_(param.data)\n",
    "            else:\n",
    "                raise Exception(f\"cannot initialize {name}\")\n",
    "        \n",
    "    @property\n",
    "    def num_parameters(self):\n",
    "        return count_parameters(self.rnn) + count_parameters(self.lin)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        rnn_out, _ = self.rnn(sentence)\n",
    "        return self.lin(rnn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleLSTM(*ARGS_837).num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(lrs: list, lengths: list, seeds: list, results: dict, model_args: tuple):    \n",
    "    for lr in lrs:\n",
    "        results[lr] = results[lr] if lr in results else {}\n",
    "        _results = results[lr]\n",
    "\n",
    "        for length in lengths:\n",
    "\n",
    "            dataset = dataset_t(length)\n",
    "            print(f\"created LSTM with {SimpleLSTM(*model_args).num_parameters} parameters\")\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            _results[length] = _results[length] if length in _results else []\n",
    "            __results = _results[length]\n",
    "\n",
    "            for seed in seeds:\n",
    "                if seed in [ s for s, _ in __results ]:\n",
    "                    continue\n",
    "\n",
    "                torch.manual_seed(seed)\n",
    "                model = SimpleLSTM(*model_args)\n",
    "                model.reset()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr)   # this has been found to converge fastest\n",
    "\n",
    "                for step in range(1, 100*1000): # cap amounts to the same number of samples seen as for qrnn\n",
    "                    sentence, target = dataset.next_batch(0, RVQE.data.TrainingStage.TRAIN)\n",
    "\n",
    "                    # transform sentence to one-hot as in the qrnn case\n",
    "                    sentence = to_one_hot(RVQE.data.targets_for_loss(sentence))            \n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(sentence.float())\n",
    "\n",
    "                    # unlike the qrnn case, we use the entire output as loss\n",
    "                    # this gives the rnn an advantage!\n",
    "                    out = out.transpose(1, 2)\n",
    "                    target = RVQE.data.targets_for_loss(target)\n",
    "                    loss = criterion(out, target)\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    if torch.isnan(loss):\n",
    "                        print(\"nan\")\n",
    "                        __results.append([seed, np.nan])\n",
    "                        break\n",
    "\n",
    "                    if loss < 0.001:\n",
    "                        __results.append([seed, step])\n",
    "                        print(f\"length {length} converged after {step} steps.\")\n",
    "                        break\n",
    "\n",
    "                    if step % 500 == 0:\n",
    "                        pass\n",
    "                        print(f\"{step:06d} {loss:.2e}\")\n",
    "\n",
    "                else:\n",
    "                    print(f\"length {length} did not converge after {step} steps.\")\n",
    "                    __results.append([seed, -1])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.3: {5: [[9120, 24], [2783, 25], [2057, 28], [6549, 31], [3201, 33]],\n",
       "  10: [[9120, 47], [2783, 48], [2057, 71], [6549, 108], [3201, 288]],\n",
       "  20: [[9120, 97], [2783, 384], [2057, 306], [6549, 311], [3201, 196]],\n",
       "  50: [[9120, 1011], [2783, 2343], [2057, 1338], [6549, 1052], [3201, 2243]]},\n",
       " 0.1: {5: [[9120, 36], [2783, 46], [2057, 42], [6549, 36], [3201, 35]],\n",
       "  10: [[9120, 87], [2783, 120], [2057, 75], [6549, 105], [3201, 211]],\n",
       "  20: [[9120, 353], [2783, 161], [2057, 136], [6549, 134], [3201, 239]],\n",
       "  50: [[9120, 463], [2783, 500], [2057, 241], [6549, 360], [3201, 555]],\n",
       "  100: [[9120, 475], [2783, 328], [2057, 741], [6549, 983], [3201, 517]],\n",
       "  200: [[9120, 1823], [2783, 462], [2057, 276], [6549, 366], [3201, 1353]],\n",
       "  500: [[9120, 4323], [2783, 606], [2057, 507], [6549, 298], [3201, 1539]],\n",
       "  1000: []},\n",
       " 0.03: {5: [[9120, 289], [2783, 328], [2057, 349], [6549, 312], [3201, 318]],\n",
       "  10: [[9120, 378], [2783, 489], [2057, 422], [6549, 465], [3201, 485]],\n",
       "  20: [[9120, 492], [2783, 677], [2057, 577], [6549, 591], [3201, 883]],\n",
       "  50: [[9120, 837], [2783, 855], [2057, 650], [6549, 861], [3201, 1590]]},\n",
       " 0.01: {5: [[9120, 849], [2783, 893], [2057, 877], [6549, 749], [3201, 880]],\n",
       "  10: [[9120, 902], [2783, 1373], [2057, 918], [6549, 1193], [3201, 1005]],\n",
       "  20: [[9120, 1169], [2783, 1579], [2057, 1406], [6549, 1380], [3201, 1644]],\n",
       "  50: [[9120, 2987], [2783, 2166], [2057, 2197], [6549, 1646], [3201, 2472]]}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lr_results_small = {}\n",
    "run_model([.3, .1, .03, .01], LENGTHS[:4], SEEDS[:5], lr_results_small, ARGS_837)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.3: {5: [[9120, 24], [2783, 25], [2057, 28], [6549, 31], [3201, 33]],\n",
       "  10: [[9120, 47], [2783, 48], [2057, 71], [6549, 108], [3201, 288]],\n",
       "  20: [[9120, 97], [2783, 384], [2057, 306], [6549, 311], [3201, 196]],\n",
       "  50: [[9120, 1011], [2783, 2343], [2057, 1338], [6549, 1052], [3201, 2243]]},\n",
       " 0.1: {5: [[9120, 36], [2783, 46], [2057, 42], [6549, 36], [3201, 35]],\n",
       "  10: [[9120, 87], [2783, 120], [2057, 75], [6549, 105], [3201, 211]],\n",
       "  20: [[9120, 353], [2783, 161], [2057, 136], [6549, 134], [3201, 239]],\n",
       "  50: [[9120, 463], [2783, 500], [2057, 241], [6549, 360], [3201, 555]]},\n",
       " 0.03: {5: [[9120, 289], [2783, 328], [2057, 349], [6549, 312], [3201, 318]],\n",
       "  10: [[9120, 378], [2783, 489], [2057, 422], [6549, 465], [3201, 485]],\n",
       "  20: [[9120, 492], [2783, 677], [2057, 577], [6549, 591], [3201, 883]],\n",
       "  50: [[9120, 837], [2783, 855], [2057, 650], [6549, 861], [3201, 1590]]},\n",
       " 0.01: {5: [[9120, 849], [2783, 893], [2057, 877], [6549, 749], [3201, 880]],\n",
       "  10: [[9120, 902], [2783, 1373], [2057, 918], [6549, 1193], [3201, 1005]],\n",
       "  20: [[9120, 1169], [2783, 1579], [2057, 1406], [6549, 1380], [3201, 1644]],\n",
       "  50: [[9120, 2987], [2783, 2166], [2057, 2197], [6549, 1646], [3201, 2472]]}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_results_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.3: 499.20000000000005, 0.1: 196.75, 0.03: 592.4, 0.01: 1414.25}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ k: np.mean([ np.mean([ t for __, t in vv if t != -1 ]) for _, vv in v.items() ]) for k, v in lr_results_small.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best learning rate for the lstm seems to be 0.1; so proceed with this setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "created LSTM with 888 parameters\n",
      "length 500 converged after 363 steps.\n",
      "000500 1.27e+00\n",
      "001000 1.03e+00\n",
      "001500 1.00e+00\n"
     ]
    }
   ],
   "source": [
    "#results_small = {.1: lr_results_small[.1].copy()}\n",
    "run_model([.1], LENGTHS, SEEDS, results_small, ARGS_837)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: {5: [[9120, 36],\n",
       "   [2783, 46],\n",
       "   [2057, 42],\n",
       "   [6549, 36],\n",
       "   [3201, 35],\n",
       "   [7063, 62],\n",
       "   [5243, 36],\n",
       "   [3102, 37],\n",
       "   [5303, 36],\n",
       "   [5819, 36],\n",
       "   [3693, 57],\n",
       "   [4884, 44],\n",
       "   [2231, 61],\n",
       "   [5514, 35],\n",
       "   [8850, 40],\n",
       "   [6861, 46],\n",
       "   [3106, 36],\n",
       "   [2378, 36],\n",
       "   [8697, 49],\n",
       "   [1821, 38],\n",
       "   [9480, 49],\n",
       "   [8483, 47],\n",
       "   [1633, 43],\n",
       "   [9678, 51],\n",
       "   [6596, 41],\n",
       "   [4509, 40],\n",
       "   [8618, 53],\n",
       "   [9765, 49],\n",
       "   [6346, 41],\n",
       "   [2969, 42]],\n",
       "  10: [[9120, 87],\n",
       "   [2783, 120],\n",
       "   [2057, 75],\n",
       "   [6549, 105],\n",
       "   [3201, 211],\n",
       "   [7063, 86],\n",
       "   [5243, 132],\n",
       "   [3102, 116],\n",
       "   [5303, 112],\n",
       "   [5819, 155],\n",
       "   [3693, 125],\n",
       "   [4884, 124],\n",
       "   [2231, 256],\n",
       "   [5514, 78],\n",
       "   [8850, 69],\n",
       "   [6861, 130],\n",
       "   [3106, 82],\n",
       "   [2378, 157],\n",
       "   [8697, 161],\n",
       "   [1821, 99],\n",
       "   [9480, 130],\n",
       "   [8483, 194],\n",
       "   [1633, 169],\n",
       "   [9678, 150],\n",
       "   [6596, 107],\n",
       "   [4509, 104],\n",
       "   [8618, 219],\n",
       "   [9765, 203],\n",
       "   [6346, 241],\n",
       "   [2969, 138]],\n",
       "  20: [[9120, 353],\n",
       "   [2783, 161],\n",
       "   [2057, 136],\n",
       "   [6549, 134],\n",
       "   [3201, 239],\n",
       "   [7063, 229],\n",
       "   [5243, 274],\n",
       "   [3102, 271],\n",
       "   [5303, 243],\n",
       "   [5819, 232],\n",
       "   [3693, 300],\n",
       "   [4884, 347],\n",
       "   [2231, 282],\n",
       "   [5514, 204],\n",
       "   [8850, 151],\n",
       "   [6861, 190],\n",
       "   [3106, 246],\n",
       "   [2378, 333],\n",
       "   [8697, 236],\n",
       "   [1821, 493],\n",
       "   [9480, 409],\n",
       "   [8483, 260],\n",
       "   [1633, 385],\n",
       "   [9678, 207],\n",
       "   [6596, 187],\n",
       "   [4509, 321],\n",
       "   [8618, 220],\n",
       "   [9765, 332],\n",
       "   [6346, 221],\n",
       "   [2969, 300]],\n",
       "  50: [[9120, 463],\n",
       "   [2783, 500],\n",
       "   [2057, 241],\n",
       "   [6549, 360],\n",
       "   [3201, 555],\n",
       "   [7063, 476],\n",
       "   [5243, 683],\n",
       "   [3102, 465],\n",
       "   [5303, 694],\n",
       "   [5819, 339],\n",
       "   [3693, 450],\n",
       "   [4884, 382],\n",
       "   [2231, 472],\n",
       "   [5514, 414],\n",
       "   [8850, 321],\n",
       "   [6861, 529],\n",
       "   [3106, 695],\n",
       "   [2378, 338],\n",
       "   [8697, 610],\n",
       "   [1821, 238],\n",
       "   [9480, 744],\n",
       "   [8483, 286],\n",
       "   [1633, 371],\n",
       "   [9678, 369],\n",
       "   [6596, 562],\n",
       "   [4509, 299],\n",
       "   [8618, 939],\n",
       "   [9765, 392],\n",
       "   [6346, 468],\n",
       "   [2969, 367]],\n",
       "  100: [[9120, 475],\n",
       "   [2783, 328],\n",
       "   [2057, 741],\n",
       "   [6549, 983],\n",
       "   [3201, 517],\n",
       "   [7063, 359],\n",
       "   [5243, 1445],\n",
       "   [3102, 420],\n",
       "   [5303, 252],\n",
       "   [5819, 369],\n",
       "   [3693, 1142],\n",
       "   [4884, 752],\n",
       "   [2231, 2242],\n",
       "   [5514, 755],\n",
       "   [8850, 792],\n",
       "   [6861, 555],\n",
       "   [3106, 426],\n",
       "   [2378, 805],\n",
       "   [8697, 409],\n",
       "   [1821, 741],\n",
       "   [9480, 489],\n",
       "   [8483, 389],\n",
       "   [1633, 1257],\n",
       "   [9678, 777],\n",
       "   [6596, 296],\n",
       "   [4509, 710],\n",
       "   [8618, 844],\n",
       "   [9765, 785],\n",
       "   [6346, 605],\n",
       "   [2969, 822]],\n",
       "  200: [[9120, 1823],\n",
       "   [2783, 462],\n",
       "   [2057, 276],\n",
       "   [6549, 366],\n",
       "   [3201, 1353],\n",
       "   [7063, 809],\n",
       "   [5243, 6714],\n",
       "   [3102, 992],\n",
       "   [5303, 815],\n",
       "   [5819, 716],\n",
       "   [3693, 586],\n",
       "   [4884, 934],\n",
       "   [2231, 3164],\n",
       "   [5514, 550],\n",
       "   [8850, 501],\n",
       "   [6861, 441],\n",
       "   [3106, 653],\n",
       "   [2378, 920],\n",
       "   [8697, 839],\n",
       "   [1821, 659],\n",
       "   [9480, 1630],\n",
       "   [8483, 528],\n",
       "   [1633, 1128],\n",
       "   [9678, 688],\n",
       "   [6596, 1794],\n",
       "   [4509, 1872],\n",
       "   [8618, 1004],\n",
       "   [9765, 1141],\n",
       "   [6346, 1737],\n",
       "   [2969, 834]],\n",
       "  500: [[9120, 4323],\n",
       "   [2783, 606],\n",
       "   [2057, 507],\n",
       "   [6549, 298],\n",
       "   [3201, 1539],\n",
       "   [7063, 795],\n",
       "   [5243, 5363],\n",
       "   [3102, 484]],\n",
       "  1000: [[9120, 691]]}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([ [key, seed, step, .0] for key in results_small[.1] for seed, step in results_small[.1][key] ], columns=[\"sentence_length\", \"seed\", \"hparams/epoch\", \"hparams/validate_best\"], index=None).to_csv(\"~/small-lstm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rvqe] *",
   "language": "python",
   "name": "conda-env-rvqe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
