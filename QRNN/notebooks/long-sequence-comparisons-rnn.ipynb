{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import RVQE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to create a RNN or LSTM with roughly 837 parameters, and compare it in the dna long sequence task implemented within RVQE.\n",
    "In either case the batch size is 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_t = lambda length: RVQE.datasets.all_datasets[\"dna\"](0, num_shards=0, batch_size=128, sentence_length=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "def to_one_hot(labels, num_classes=2**3):\n",
    "    return torch.eye(num_classes)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = [9120, 2783, 2057, 6549, 3201, 7063, 5243, 3102, 5303, 5819, 3693, 4884, 2231, 5514, 8850, 6861, 3106, 2378, 8697, 1821, 9480, 8483, 1633, 9678, 6596, 4509, 8618, 9765, 6346, 2969];\n",
    "LENGTHS = [5, 10, 20, 50, 100, 200, 500, 1000];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE_837 = 22\n",
    "NUM_LAYERS_837 = 1\n",
    "ARGS_837 = (HIDDEN_SIZE_837, NUM_LAYERS_837)\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    \"\"\"\n",
    "        This is a very simplistic RNN setup. We found a single layer performs\n",
    "        much better than two layers with a smaller hidden size.\n",
    "        Without doubt one can improve the performance of this model.\n",
    "        Yet we didn't optimize the QRNN setup for the task at hand either.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size: int, num_layers: int, io_size=2**3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size=io_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.lin = nn.Linear(hidden_size, io_size)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.lin.reset_parameters()\n",
    "        for name, param in self.rnn.named_parameters():\n",
    "            # give an orthogonal start\n",
    "            if \"weight_hh\" in name:\n",
    "                torch.nn.init.orthogonal_(param.data)\n",
    "            elif \"bias\" in name:\n",
    "                param.data.fill_(0)\n",
    "            elif \"weight_ih\" in name:\n",
    "                torch.nn.init.xavier_uniform_(param.data)\n",
    "            else:\n",
    "                raise Exception(f\"cannot initialize {name}\")\n",
    "        \n",
    "    @property\n",
    "    def num_parameters(self):\n",
    "        return count_parameters(self.rnn) + count_parameters(self.lin)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        rnn_out, _ = self.rnn(sentence)\n",
    "        return self.lin(rnn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleRNN(*ARGS_837).num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(lrs: list, lengths: list, seeds: list, results: dict, model_args: tuple):\n",
    "    for lr in lrs:\n",
    "        results[lr] = results[lr] if lr in results else {}\n",
    "        _results = results[lr]\n",
    "\n",
    "        for length in lengths:\n",
    "\n",
    "            dataset = dataset_t(length)\n",
    "            print(f\"created RNN with {SimpleRNN(*model_args).num_parameters} parameters\")\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "            _results[length] = _results[length] if length in _results else []\n",
    "            __results = _results[length]\n",
    "\n",
    "            for seed in seeds:\n",
    "                if seed in [ s for s, _ in __results ]:\n",
    "                    continue\n",
    "\n",
    "                torch.manual_seed(seed)\n",
    "                model = SimpleRNN(*model_args)\n",
    "                model.reset()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr)   # this has been found to converge fastest\n",
    "\n",
    "                for step in range(1, 100*1000): # cap amounts to the same number of samples seen as for qrnn\n",
    "                    sentence, target = dataset.next_batch(0, RVQE.data.TrainingStage.TRAIN)\n",
    "\n",
    "                    # transform sentence to one-hot as in the qrnn case\n",
    "                    sentence = to_one_hot(RVQE.data.targets_for_loss(sentence))            \n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(sentence.float())\n",
    "\n",
    "                    # unlike the qrnn case, we use the entire output as loss\n",
    "                    # this gives the rnn an advantage!\n",
    "                    out = out.transpose(1, 2)\n",
    "                    target = RVQE.data.targets_for_loss(target)\n",
    "                    loss = criterion(out, target)\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    if torch.isnan(loss):\n",
    "                        print(\"nan\")\n",
    "                        __results.append([seed, np.nan])\n",
    "                        break\n",
    "\n",
    "                    if loss < 0.001:\n",
    "                        __results.append([seed, step])\n",
    "                        print(f\"length {length} converged after {step} steps.\")\n",
    "                        break\n",
    "\n",
    "                    if step % 500 == 0:\n",
    "                        pass\n",
    "                        print(f\"{step:06d} {loss:.2e}\")\n",
    "\n",
    "                else:\n",
    "                    print(f\"length {length} did not converge after {step} steps.\")\n",
    "                    __results.append([seed, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "000500 6.50e-01\n",
      "001000 2.66e-01\n",
      "001500 2.45e-01\n",
      "002000 2.54e-01\n",
      "002500 1.05e-02\n",
      "003000 4.35e-03\n",
      "003500 2.53e-03\n",
      "004000 1.47e-03\n",
      "length 50 converged after 4431 steps.\n",
      "000500 5.80e-01\n",
      "001000 5.81e-01\n",
      "001500 6.13e-01\n",
      "002000 1.36e-02\n",
      "002500 5.21e-03\n",
      "003000 2.56e-03\n",
      "003500 1.79e-03\n",
      "004000 1.12e-03\n",
      "length 50 converged after 4067 steps.\n",
      "000500 6.36e-01\n",
      "001000 2.54e-01\n",
      "001500 1.23e-01\n",
      "002000 9.49e-03\n",
      "002500 3.57e-03\n",
      "003000 2.07e-03\n",
      "003500 1.25e-03\n",
      "length 50 converged after 3661 steps.\n",
      "000500 5.72e-01\n",
      "001000 2.40e-02\n",
      "001500 4.81e-03\n",
      "002000 2.28e-03\n",
      "002500 1.34e-03\n",
      "length 50 converged after 2761 steps.\n",
      "000500 8.01e-01\n",
      "001000 6.17e-01\n",
      "001500 2.64e-01\n",
      "002000 3.75e-01\n",
      "002500 2.26e-02\n",
      "003000 5.81e-03\n",
      "003500 3.00e-03\n",
      "004000 1.70e-03\n",
      "004500 1.17e-03\n",
      "length 50 converged after 4616 steps.\n"
     ]
    }
   ],
   "source": [
    "#lr_results_small = {}\n",
    "run_with_lrs([.03, .01, .003], LENGTHS[:4], SEEDS[:5], lr_results_small, ARGS_837)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.03: {5: [[9120, 72], [2783, 59], [2057, 54], [6549, 58], [3201, 53]],\n",
       "  10: [[9120, 189], [2783, 212], [2057, 265], [6549, 266], [3201, 205]],\n",
       "  20: [[9120, 474], [2783, 1554], [2057, 1447], [6549, 529], [3201, 884]],\n",
       "  50: [[9120, 8021], [2783, 5704], [2057, -1], [6549, -1], [3201, 14176]]},\n",
       " 0.01: {5: [[9120, 414], [2783, 417], [2057, 374], [6549, 382], [3201, 386]],\n",
       "  10: [[9120, 582], [2783, 573], [2057, 569], [6549, 554], [3201, 555]],\n",
       "  20: [[9120, 803], [2783, 1118], [2057, 1109], [6549, 835], [3201, 1055]],\n",
       "  50: [[9120, 3187], [2783, 1709], [2057, 5477], [6549, 5048], [3201, 8736]]},\n",
       " 0.003: {5: [[9120, 1163],\n",
       "   [2783, 1219],\n",
       "   [2057, 1158],\n",
       "   [6549, 1224],\n",
       "   [3201, 1178]],\n",
       "  10: [[9120, 1577], [2783, 1434], [2057, 1521], [6549, 1553], [3201, 1534]],\n",
       "  20: [[9120, 1973], [2783, 2167], [2057, 2096], [6549, 1660], [3201, 1838]],\n",
       "  50: [[9120, 4431], [2783, 4067], [2057, 3661], [6549, 2761], [3201, 4616]]}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_results_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.03: 2641.1333333333337, 0.01: 1694.1499999999999, 0.003: 2141.55}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ k: np.mean([ np.mean([ t for __, t in vv if t != -1 ]) for _, vv in v.items() ]) for k, v in lr_results_small.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.01: {5: [[9120, 414], [2783, 417], [2057, 374], [6549, 382], [3201, 386]],\n",
       "  10: [[9120, 582], [2783, 573], [2057, 569], [6549, 554], [3201, 555]],\n",
       "  20: [[9120, 803], [2783, 1118], [2057, 1109], [6549, 835], [3201, 1055]],\n",
       "  50: [[9120, 3187], [2783, 1709], [2057, 5477], [6549, 5048], [3201, 8736]],\n",
       "  100: [[9120, 6362], [2783, 7928], [2057, 4586], [6549, 2477], [3201, 7326]],\n",
       "  200: [[9120, 3752], [2783, 2476], [2057, 11872], [6549, 5613], [3201, 6212]],\n",
       "  500: [[9120, 3283], [2783, 14294]]}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "created RNN with 888 parameters\n",
      "000500 1.32e+00\n",
      "001000 1.47e+00\n",
      "001500 6.34e-01\n",
      "002000 3.27e-01\n",
      "002500 2.89e-01\n"
     ]
    }
   ],
   "source": [
    "#results_small = {.01: lr_results_small[.01].copy()}\n",
    "run_model([.01], LENGTHS, SEEDS[:5], results_small, ARGS_837)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([ [key, seed, step, .0] for key in results_small[.01] for seed, step in results_small[.01][key] ], columns=[\"sentence_length\", \"seed\", \"hparams/epoch\", \"hparams/validate_best\"], index=None).to_csv(\"~/small-rnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(5, [[9120, 48], [2783, 45], [2057, 43], [6549, 57], [3201, 53], [7063, 65], [5243, 44], [3102, 41], [5303, 53], [5819, 50], [3693, 47], [4884, 47], [2231, 49], [5514, 46], [8850, 58], [6861, 42], [3106, 40], [2378, 68], [8697, 44], [1821, 46], [9480, 47], [8483, 53], [1633, 53], [9678, 49], [6596, 43], [4509, 43], [8618, 46], [9765, 46], [6346, 44], [2969, 49]]), (10, [[9120, 386], [2783, 276], [2057, 285], [6549, 304], [3201, 387], [7063, 432], [5243, 216], [3102, 352], [5303, 298], [5819, 415], [3693, 262], [4884, 317], [2231, 386], [5514, 342], [8850, 436], [6861, 424], [3106, 294], [2378, 285], [8697, 331], [1821, 348], [9480, 299], [8483, 419], [1633, 374], [9678, 401], [6596, 412], [4509, 422], [8618, 385], [9765, 277], [6346, 602], [2969, 302]]), (20, [[9120, 15999], [2783, 15999], [2057, 15999], [6549, 15999], [3201, 15999], [7063, 15999], [5243, 15999], [3102, 15999], [5303, 15999], [5819, 15999], [3693, 15999], [4884, 15999], [2231, 15999], [5514, 15999], [8850, 15999], [6861, 15999], [3106, 15999], [2378, 15999], [8697, 15999], [1821, 15999], [9480, 15999], [8483, 15999], [1633, 15999], [9678, 15999], [6596, 15999], [4509, 15999], [8618, 15999], [9765, 15999], [6346, 15999], [2969, 15999]]), (50, [[9120, 15999], [2783, 15999], [2057, 15999], [6549, 15999], [3201, 15999], [7063, 15999], [5243, 15999], [3102, 15999], [5303, 15999], [5819, 15999], [3693, 15999], [4884, 15999], [2231, 15999], [5514, 15999], [8850, 15999], [6861, 15999], [3106, 15999], [2378, 15999], [8697, 15999], [1821, 15999], [9480, 15999], [8483, 15999], [1633, 15999], [9678, 15999], [6596, 15999], [4509, 15999], [8618, 15999], [9765, 15999], [6346, 15999], [2969, 15999]]), (100, [[9120, 15999], [2783, 15999], [2057, 15999], [6549, 15999], [3201, 15999], [7063, 15999], [5243, 15999], [3102, 15999], [5303, 15999], [5819, 15999], [3693, 15999], [4884, 15999]])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.items() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rvqe] *",
   "language": "python",
   "name": "conda-env-rvqe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
